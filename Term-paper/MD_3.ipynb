{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d69947",
   "metadata": {},
   "source": [
    "# Read and merge all CSV files from `data` (only import pandas)\n",
    "\n",
    "This notebook reads every CSV in `Term-paper/data` using only `pandas` as an explicit import,\n",
    "lists files using the Jupyter/IPython shell, then merges them into a single DataFrame.\n",
    "If DataFrames share column names the merge uses those columns; otherwise DataFrames are concatenated side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4f6567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CPI.csv -> (944, 1)\n",
      "Loaded SCE-Apr-2014.csv -> (1311, 29)\n",
      "Loaded SCE-Apr-2015.csv -> (1283, 29)\n",
      "Loaded SCE-Apr-2016.csv -> (1214, 29)\n",
      "Loaded SCE-Apr-2017.csv -> (1276, 29)\n",
      "Loaded SCE-Apr-2018.csv -> (1300, 29)\n",
      "Loaded SCE-Apr-2019.csv -> (1336, 29)\n",
      "Loaded SCE-Apr-2020.csv -> (1300, 29)\n",
      "Loaded SCE-Apr-2021.csv -> (1243, 29)\n",
      "Loaded SCE-Apr-2022.csv -> (1269, 29)\n",
      "Loaded SCE-Apr-2023.csv -> (1255, 29)\n",
      "Loaded SCE-Apr-2024.csv -> (1082, 29)\n",
      "Loaded SCE-Aug-2013.csv -> (1769, 29)\n",
      "Loaded SCE-Aug-2014.csv -> (1352, 29)\n",
      "Loaded SCE-Aug-2015.csv -> (1226, 29)\n",
      "Loaded SCE-Aug-2016.csv -> (1271, 29)\n",
      "Loaded SCE-Aug-2017.csv -> (1344, 29)\n",
      "Loaded SCE-Aug-2018.csv -> (1331, 29)\n",
      "Loaded SCE-Aug-2019.csv -> (1290, 29)\n",
      "Loaded SCE-Aug-2020.csv -> (1193, 29)\n",
      "Loaded SCE-Aug-2021.csv -> (1265, 29)\n",
      "Loaded SCE-Aug-2022.csv -> (1300, 29)\n",
      "Loaded SCE-Aug-2023.csv -> (1130, 29)\n",
      "Loaded SCE-Aug-2024.csv -> (1108, 29)\n",
      "Loaded SCE-Dec-2013.csv -> (1350, 29)\n",
      "Loaded SCE-Dec-2014.csv -> (1302, 29)\n",
      "Loaded SCE-Dec-2015.csv -> (1201, 29)\n",
      "Loaded SCE-Dec-2016.csv -> (1359, 29)\n",
      "Loaded SCE-Dec-2017.csv -> (1273, 29)\n",
      "Loaded SCE-Dec-2018.csv -> (1268, 29)\n",
      "Loaded SCE-Dec-2019.csv -> (1262, 29)\n",
      "Loaded SCE-Dec-2020.csv -> (1337, 29)\n",
      "Loaded SCE-Dec-2021.csv -> (1283, 29)\n",
      "Loaded SCE-Dec-2022.csv -> (1158, 29)\n",
      "Loaded SCE-Dec-2023.csv -> (1120, 29)\n",
      "Loaded SCE-Dec-2024.csv -> (976, 29)\n",
      "Loaded SCE-Feb-2014.csv -> (1295, 29)\n",
      "Loaded SCE-Feb-2015.csv -> (1314, 29)\n",
      "Loaded SCE-Feb-2016.csv -> (1178, 29)\n",
      "Loaded SCE-Feb-2017.csv -> (1341, 29)\n",
      "Loaded SCE-Feb-2018.csv -> (1322, 29)\n",
      "Loaded SCE-Feb-2019.csv -> (1359, 29)\n",
      "Loaded SCE-Feb-2020.csv -> (1330, 29)\n",
      "Loaded SCE-Feb-2021.csv -> (1243, 29)\n",
      "Loaded SCE-Feb-2022.csv -> (1210, 29)\n",
      "Loaded SCE-Feb-2023.csv -> (1208, 29)\n",
      "Loaded SCE-Feb-2024.csv -> (1129, 29)\n",
      "Loaded SCE-Jan-2014.csv -> (1328, 29)\n",
      "Loaded SCE-Jan-2015.csv -> (1308, 29)\n",
      "Loaded SCE-Jan-2016.csv -> (1232, 29)\n",
      "Loaded SCE-Jan-2017.csv -> (1358, 29)\n",
      "Loaded SCE-Jan-2018.csv -> (1323, 29)\n",
      "Loaded SCE-Jan-2019.csv -> (1372, 29)\n",
      "Loaded SCE-Jan-2020.csv -> (1317, 29)\n",
      "Loaded SCE-Jan-2021.csv -> (1259, 29)\n",
      "Loaded SCE-Jan-2022.csv -> (1235, 29)\n",
      "Loaded SCE-Jan-2023.csv -> (1178, 29)\n",
      "Loaded SCE-Jan-2024.csv -> (1128, 29)\n",
      "Loaded SCE-Jul-2013.csv -> (1197, 29)\n",
      "Loaded SCE-Jul-2014.csv -> (1373, 29)\n",
      "Loaded SCE-Jul-2015.csv -> (1256, 29)\n",
      "Loaded SCE-Jul-2016.csv -> (1305, 29)\n",
      "Loaded SCE-Jul-2017.csv -> (1354, 29)\n",
      "Loaded SCE-Jul-2018.csv -> (1330, 29)\n",
      "Loaded SCE-Jul-2019.csv -> (1318, 29)\n",
      "Loaded SCE-Jul-2020.csv -> (1205, 29)\n",
      "Loaded SCE-Jul-2021.csv -> (1239, 29)\n",
      "Loaded SCE-Jul-2022.csv -> (1305, 29)\n",
      "Loaded SCE-Jul-2023.csv -> (1130, 29)\n",
      "Loaded SCE-Jul-2024.csv -> (1099, 29)\n",
      "Loaded SCE-Jun-2013.csv -> (1253, 29)\n",
      "Loaded SCE-Jun-2014.csv -> (1302, 29)\n",
      "Loaded SCE-Jun-2015.csv -> (1271, 29)\n",
      "Loaded SCE-Jun-2016.csv -> (1261, 29)\n",
      "Loaded SCE-Jun-2017.csv -> (1349, 29)\n",
      "Loaded SCE-Jun-2018.csv -> (1306, 29)\n",
      "Loaded SCE-Jun-2019.csv -> (1330, 29)\n",
      "Loaded SCE-Jun-2020.csv -> (1200, 29)\n",
      "Loaded SCE-Jun-2021.csv -> (1297, 29)\n",
      "Loaded SCE-Jun-2022.csv -> (1217, 29)\n",
      "Loaded SCE-Jun-2023.csv -> (1159, 29)\n",
      "Loaded SCE-Jun-2024.csv -> (1086, 29)\n",
      "Loaded SCE-Mar-2014.csv -> (1309, 29)\n",
      "Loaded SCE-Mar-2015.csv -> (1288, 29)\n",
      "Loaded SCE-Mar-2016.csv -> (1242, 29)\n",
      "Loaded SCE-Mar-2017.csv -> (1365, 29)\n",
      "Loaded SCE-Mar-2018.csv -> (1315, 29)\n",
      "Loaded SCE-Mar-2019.csv -> (1368, 29)\n",
      "Loaded SCE-Mar-2020.csv -> (1300, 29)\n",
      "Loaded SCE-Mar-2021.csv -> (1221, 29)\n",
      "Loaded SCE-Mar-2022.csv -> (1273, 29)\n",
      "Loaded SCE-Mar-2023.csv -> (1254, 29)\n",
      "Loaded SCE-Mar-2024.csv -> (1120, 29)\n",
      "Loaded SCE-May-2014.csv -> (1280, 29)\n",
      "Loaded SCE-May-2015.csv -> (1276, 29)\n",
      "Loaded SCE-May-2016.csv -> (1259, 29)\n",
      "Loaded SCE-May-2017.csv -> (1349, 29)\n",
      "Loaded SCE-May-2018.csv -> (1312, 29)\n",
      "Loaded SCE-May-2019.csv -> (1321, 29)\n",
      "Loaded SCE-May-2020.csv -> (1266, 29)\n",
      "Loaded SCE-May-2021.csv -> (1234, 29)\n",
      "Loaded SCE-May-2022.csv -> (1215, 29)\n",
      "Loaded SCE-May-2023.csv -> (1215, 29)\n",
      "Loaded SCE-May-2024.csv -> (1092, 29)\n",
      "Loaded SCE-Nov-2013.csv -> (1541, 29)\n",
      "Loaded SCE-Nov-2014.csv -> (1312, 29)\n",
      "Loaded SCE-Nov-2015.csv -> (1242, 29)\n",
      "Loaded SCE-Nov-2016.csv -> (1321, 29)\n",
      "Loaded SCE-Nov-2017.csv -> (1337, 29)\n",
      "Loaded SCE-Nov-2018.csv -> (1323, 29)\n",
      "Loaded SCE-Nov-2019.csv -> (1283, 29)\n",
      "Loaded SCE-Nov-2020.csv -> (1233, 29)\n",
      "Loaded SCE-Nov-2021.csv -> (1281, 29)\n",
      "Loaded SCE-Nov-2022.csv -> (1184, 29)\n",
      "Loaded SCE-Nov-2023.csv -> (1098, 29)\n",
      "Loaded SCE-Nov-2024.csv -> (1037, 29)\n",
      "Loaded SCE-Oct-2013.csv -> (1538, 29)\n",
      "Loaded SCE-Oct-2014.csv -> (1328, 29)\n",
      "Loaded SCE-Oct-2015.csv -> (1248, 29)\n",
      "Loaded SCE-Oct-2016.csv -> (1319, 29)\n",
      "Loaded SCE-Oct-2017.csv -> (1377, 29)\n",
      "Loaded SCE-Oct-2018.csv -> (1354, 29)\n",
      "Loaded SCE-Oct-2019.csv -> (1309, 29)\n",
      "Loaded SCE-Oct-2020.csv -> (1197, 29)\n",
      "Loaded SCE-Oct-2021.csv -> (1283, 29)\n",
      "Loaded SCE-Oct-2022.csv -> (1181, 29)\n",
      "Loaded SCE-Oct-2023.csv -> (1124, 29)\n",
      "Loaded SCE-Oct-2024.csv -> (1076, 29)\n",
      "Loaded SCE-Sep-2013.csv -> (1529, 29)\n",
      "Loaded SCE-Sep-2014.csv -> (1320, 29)\n",
      "Loaded SCE-Sep-2015.csv -> (1262, 29)\n",
      "Loaded SCE-Sep-2016.csv -> (1319, 29)\n",
      "Loaded SCE-Sep-2017.csv -> (1325, 29)\n",
      "Loaded SCE-Sep-2018.csv -> (1302, 29)\n",
      "Loaded SCE-Sep-2019.csv -> (1299, 29)\n",
      "Loaded SCE-Sep-2020.csv -> (1166, 29)\n",
      "Loaded SCE-Sep-2021.csv -> (1261, 29)\n",
      "Loaded SCE-Sep-2022.csv -> (1271, 29)\n",
      "Loaded SCE-Sep-2023.csv -> (1112, 29)\n",
      "Loaded SCE-Sep-2024.csv -> (1089, 29)\n",
      "Final merged shape: (176101, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the data directory (relative to the repository root)\n",
    "# Use relative path to data directory\n",
    "data_path = 'data'  # Since we're already in the Term-paper folder\n",
    "\n",
    "# List files using the IPython shell\n",
    "files = get_ipython().getoutput(f'ls {data_path}/*.csv')\n",
    "\n",
    "# List files using the IPython shell so we don't import os/pathlib/glob explicitly\n",
    "files = []\n",
    "try:\n",
    "    # List the files in the data_path directory\n",
    "    files = get_ipython().getoutput(f'ls \"{data_path}\"')\n",
    "except Exception:\n",
    "    # If running outside IPython this will fail; keep files empty so we don't error out\n",
    "    files = []\n",
    "\n",
    "# Filter CSV files\n",
    "csv_files = [f for f in files if isinstance(f, str) and f.lower().endswith('.csv')]\n",
    "\n",
    "if not csv_files:\n",
    "    print('No CSV files found in', data_path)\n",
    "else:\n",
    "    dfs = []  # list of (filename, df)\n",
    "    for fname in csv_files:\n",
    "        full = f'{data_path}/{fname}'\n",
    "        try:\n",
    "            df = pd.read_csv(full, sep=';')\n",
    "            dfs.append((fname, df))\n",
    "            print('Loaded', fname, '->', df.shape)\n",
    "        except Exception as e:\n",
    "            print('Failed to read', full, ':', e)\n",
    "\n",
    "    # If nothing successfully read, create empty merged_df\n",
    "    if not dfs:\n",
    "        merged_df = pd.DataFrame()\n",
    "    else:\n",
    "        # Start with first DataFrame\n",
    "        merged_df = dfs[0][1]\n",
    "        for name, df in dfs[1:]:\n",
    "            # find common columns to merge on\n",
    "            common = [c for c in merged_df.columns if c in df.columns]\n",
    "            if common:\n",
    "                # merge on all common columns (outer join to keep data)\n",
    "                merged_df = pd.merge(merged_df, df, how='outer', on=common)\n",
    "            else:\n",
    "                # no common columns: concatenate side-by-side (columns may be duplicated)\n",
    "                merged_df = pd.concat([merged_df, df], axis=1)\n",
    "\n",
    "    print('Final merged shape:', merged_df.shape)\n",
    "\n",
    "# keep merged_df available in the notebook namespace even if no files were found\n",
    "try:\n",
    "    merged_df\n",
    "except NameError:\n",
    "    merged_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30dd117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE,CPI</th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000220</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000224</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000234</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000238</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000238</td>\n",
       "      <td>201307</td>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176096</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75025299</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176097</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75025320</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75025337</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176099</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75025373</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75025376</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176101 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE,CPI    userid     wid        date  weight  female  educ   age  \\\n",
       "0           NaN  70000220  201306  2013-06-04    16.3     1.0   3.0  28.0   \n",
       "1           NaN  70000224  201306  2013-06-03     0.2     0.0   4.0  65.0   \n",
       "2           NaN  70000234  201306  2013-06-17     4.1     1.0   3.0  41.0   \n",
       "3           NaN  70000238  201306  2013-06-13     3.0     0.0   3.0  74.0   \n",
       "4           NaN  70000238  201307  2013-07-10     1.9     0.0   3.0  74.0   \n",
       "...         ...       ...     ...         ...     ...     ...   ...   ...   \n",
       "176096      NaN  75025299  202412  2024-12-19     0.6     1.0   3.0  33.0   \n",
       "176097      NaN  75025320  202412  2024-12-05     0.8     1.0   4.0  56.0   \n",
       "176098      NaN  75025337  202412  2024-12-21     1.0     1.0   3.0  68.0   \n",
       "176099      NaN  75025373  202412  2024-12-09     2.4     1.0   2.0  58.0   \n",
       "176100      NaN  75025376  202412  2024-12-12     0.5     1.0   4.0  38.0   \n",
       "\n",
       "        hispanic  black  ...  num_lit_q3  num_lit_q3_correct  num_lit_q5  \\\n",
       "0            0.0    1.0  ...       100.0                 0.0       100.0   \n",
       "1            0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "2            0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "3            0.0    0.0  ...        10.0                 1.0         1.0   \n",
       "4            0.0    0.0  ...         NaN                 NaN         NaN   \n",
       "...          ...    ...  ...         ...                 ...         ...   \n",
       "176096       0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "176097       1.0    0.0  ...        10.0                 1.0       100.0   \n",
       "176098       0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "176099       0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "176100       0.0    0.0  ...        10.0                 1.0       100.0   \n",
       "\n",
       "        num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                      1.0         5.0                 1.0         NaN   \n",
       "1                      1.0         5.0                 1.0         NaN   \n",
       "2                      1.0         5.0                 1.0         NaN   \n",
       "3                      0.0         5.0                 1.0         NaN   \n",
       "4                      NaN         NaN                 NaN         NaN   \n",
       "...                    ...         ...                 ...         ...   \n",
       "176096                 1.0         5.0                 1.0         2.0   \n",
       "176097                 1.0         5.0                 1.0         3.0   \n",
       "176098                 1.0         5.0                 1.0         3.0   \n",
       "176099                 1.0         1.0                 0.0         3.0   \n",
       "176100                 1.0         2.0                 0.0         3.0   \n",
       "\n",
       "        num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  \n",
       "0                      NaN         NaN                 NaN  \n",
       "1                      NaN         NaN                 NaN  \n",
       "2                      NaN         NaN                 NaN  \n",
       "3                      NaN         NaN                 NaN  \n",
       "4                      NaN         NaN                 NaN  \n",
       "...                    ...         ...                 ...  \n",
       "176096                 0.0         2.0                 1.0  \n",
       "176097                 1.0         2.0                 1.0  \n",
       "176098                 1.0         2.0                 1.0  \n",
       "176099                 1.0         2.0                 1.0  \n",
       "176100                 1.0         2.0                 1.0  \n",
       "\n",
       "[176101 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e51c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_df shape: (176101, 30)\n"
     ]
    }
   ],
   "source": [
    "# Quick inspection\n",
    "merged_df.head()\n",
    "\n",
    "# Show shape explicitly\n",
    "print('merged_df shape:', merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45954b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('DATE,CPI', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1becfc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 176101 entries, 0 to 176100\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   userid              176101 non-null  int64  \n",
      " 1   wid                 176101 non-null  int64  \n",
      " 2   date                176101 non-null  object \n",
      " 3   weight              176036 non-null  float64\n",
      " 4   female              176025 non-null  float64\n",
      " 5   educ                175359 non-null  float64\n",
      " 6   age                 176001 non-null  float64\n",
      " 7   hispanic            175953 non-null  float64\n",
      " 8   black               176095 non-null  float64\n",
      " 9   couple              163109 non-null  float64\n",
      " 10  num_kids            176072 non-null  float64\n",
      " 11  owner               23357 non-null   float64\n",
      " 12  inflation           175419 non-null  float64\n",
      " 13  house_price_change  175796 non-null  float64\n",
      " 14  prob_stocks_up      175141 non-null  float64\n",
      " 15  num_lit_q1          23303 non-null   float64\n",
      " 16  num_lit_q1_correct  23303 non-null   float64\n",
      " 17  num_lit_q2          23272 non-null   float64\n",
      " 18  num_lit_q2_correct  23272 non-null   float64\n",
      " 19  num_lit_q3          23219 non-null   float64\n",
      " 20  num_lit_q3_correct  23219 non-null   float64\n",
      " 21  num_lit_q5          23243 non-null   float64\n",
      " 22  num_lit_q5_correct  23243 non-null   float64\n",
      " 23  num_lit_q6          23151 non-null   float64\n",
      " 24  num_lit_q6_correct  23151 non-null   float64\n",
      " 25  num_lit_q8          17985 non-null   float64\n",
      " 26  num_lit_q8_correct  17985 non-null   float64\n",
      " 27  num_lit_q9          17934 non-null   float64\n",
      " 28  num_lit_q9_correct  17934 non-null   float64\n",
      "dtypes: float64(26), int64(2), object(1)\n",
      "memory usage: 39.0+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc2092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique user IDs: 23369\n"
     ]
    }
   ],
   "source": [
    "num_nunique_id = merged_df['userid'].nunique()\n",
    "print('Number of unique user IDs:', num_nunique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611f5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafe391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SCE-Sep-2013.csv -> (1529, 29)\n",
      "Loaded SCE-Nov-2022.csv -> (1184, 29)\n",
      "Loaded SCE-Jan-2021.csv -> (1259, 29)\n",
      "Loaded CPI.csv -> (944, 1)\n",
      "Loaded SCE-Jan-2020.csv -> (1317, 29)\n",
      "Loaded SCE-Nov-2023.csv -> (1098, 29)\n",
      "Loaded SCE-Nov-2021.csv -> (1281, 29)\n",
      "Loaded SCE-Aug-2018.csv -> (1331, 29)\n",
      "Loaded SCE-Aug-2024.csv -> (1108, 29)\n",
      "Loaded SCE-Jul-2013.csv -> (1197, 29)\n",
      "Loaded SCE-Jan-2022.csv -> (1235, 29)\n",
      "Loaded SCE-Dec-2019.csv -> (1262, 29)\n",
      "Loaded SCE-Dec-2018.csv -> (1268, 29)\n",
      "Loaded SCE-Dec-2024.csv -> (976, 29)\n",
      "Loaded SCE-Jan-2023.csv -> (1178, 29)\n",
      "Loaded SCE-Aug-2019.csv -> (1290, 29)\n",
      "Loaded SCE-Nov-2020.csv -> (1233, 29)\n",
      "Loaded SCE-Sep-2015.csv -> (1262, 29)\n",
      "Loaded SCE-Mar-2017.csv -> (1365, 29)\n",
      "Loaded SCE-Nov-2024.csv -> (1037, 29)\n",
      "Loaded SCE-Nov-2018.csv -> (1323, 29)\n",
      "Loaded SCE-Aug-2021.csv -> (1265, 29)\n",
      "Loaded SCE-Jul-2016.csv -> (1305, 29)\n",
      "Loaded SCE-Apr-2015.csv -> (1283, 29)\n",
      "Loaded SCE-May-2014.csv -> (1280, 29)\n",
      "Loaded SCE-Dec-2020.csv -> (1337, 29)\n",
      "Loaded SCE-Dec-2021.csv -> (1283, 29)\n",
      "Loaded SCE-May-2015.csv -> (1276, 29)\n",
      "Loaded SCE-Apr-2014.csv -> (1311, 29)\n",
      "Loaded SCE-Jul-2017.csv -> (1354, 29)\n",
      "Loaded SCE-Aug-2020.csv -> (1193, 29)\n",
      "Loaded SCE-Nov-2019.csv -> (1283, 29)\n",
      "Loaded SCE-Mar-2016.csv -> (1242, 29)\n",
      "Loaded SCE-Sep-2014.csv -> (1320, 29)\n",
      "Loaded SCE-Sep-2016.csv -> (1319, 29)\n",
      "Loaded SCE-Mar-2014.csv -> (1309, 29)\n",
      "Loaded SCE-Aug-2022.csv -> (1300, 29)\n",
      "Loaded SCE-Jan-2018.csv -> (1323, 29)\n",
      "Loaded SCE-Jul-2015.csv -> (1256, 29)\n",
      "Loaded SCE-Jan-2024.csv -> (1128, 29)\n",
      "Loaded SCE-Apr-2016.csv -> (1214, 29)\n",
      "Loaded SCE-May-2017.csv -> (1349, 29)\n",
      "Loaded SCE-Dec-2023.csv -> (1120, 29)\n",
      "Loaded SCE-Dec-2022.csv -> (1158, 29)\n",
      "Loaded SCE-May-2016.csv -> (1259, 29)\n",
      "Loaded SCE-Apr-2017.csv -> (1276, 29)\n",
      "Loaded SCE-Jul-2014.csv -> (1373, 29)\n",
      "Loaded SCE-Jan-2019.csv -> (1372, 29)\n",
      "Loaded SCE-Aug-2023.csv -> (1130, 29)\n",
      "Loaded SCE-Mar-2015.csv -> (1288, 29)\n",
      "Loaded SCE-Sep-2017.csv -> (1325, 29)\n",
      "Loaded SCE-Oct-2022.csv -> (1181, 29)\n",
      "Loaded SCE-Jun-2020.csv -> (1200, 29)\n",
      "Loaded SCE-Jun-2021.csv -> (1297, 29)\n",
      "Loaded SCE-Oct-2023.csv -> (1124, 29)\n",
      "Loaded SCE-Feb-2024.csv -> (1129, 29)\n",
      "Loaded SCE-Feb-2018.csv -> (1322, 29)\n",
      "Loaded SCE-Oct-2021.csv -> (1283, 29)\n",
      "Loaded SCE-Jun-2023.csv -> (1159, 29)\n",
      "Loaded SCE-Jun-2022.csv -> (1217, 29)\n",
      "Loaded SCE-Oct-2020.csv -> (1197, 29)\n",
      "Loaded SCE-Feb-2019.csv -> (1359, 29)\n",
      "Loaded SCE-Feb-2021.csv -> (1243, 29)\n",
      "Loaded SCE-Oct-2024.csv -> (1076, 29)\n",
      "Loaded SCE-Oct-2018.csv -> (1354, 29)\n",
      "Loaded SCE-Oct-2019.csv -> (1309, 29)\n",
      "Loaded SCE-Feb-2020.csv -> (1330, 29)\n",
      "Loaded SCE-Feb-2022.csv -> (1210, 29)\n",
      "Loaded SCE-Jun-2019.csv -> (1330, 29)\n",
      "Loaded SCE-Jun-2018.csv -> (1306, 29)\n",
      "Loaded SCE-Jun-2024.csv -> (1086, 29)\n",
      "Loaded SCE-Feb-2023.csv -> (1208, 29)\n",
      "Loaded SCE-Oct-2017.csv -> (1377, 29)\n",
      "Loaded SCE-Jun-2015.csv -> (1271, 29)\n",
      "Loaded SCE-Jun-2014.csv -> (1302, 29)\n",
      "Loaded SCE-Oct-2016.csv -> (1319, 29)\n",
      "Loaded SCE-Oct-2014.csv -> (1328, 29)\n",
      "Loaded SCE-Jun-2016.csv -> (1261, 29)\n",
      "Loaded SCE-Jun-2017.csv -> (1349, 29)\n",
      "Loaded SCE-Oct-2015.csv -> (1248, 29)\n",
      "Loaded SCE-Feb-2014.csv -> (1295, 29)\n",
      "Loaded SCE-Jun-2013.csv -> (1253, 29)\n",
      "Loaded SCE-Feb-2015.csv -> (1314, 29)\n",
      "Loaded SCE-Feb-2017.csv -> (1341, 29)\n",
      "Loaded SCE-Oct-2013.csv -> (1538, 29)\n",
      "Loaded SCE-Feb-2016.csv -> (1178, 29)\n",
      "Loaded SCE-Mar-2018.csv -> (1315, 29)\n",
      "Loaded SCE-Mar-2024.csv -> (1120, 29)\n",
      "Loaded SCE-Nov-2017.csv -> (1337, 29)\n",
      "Loaded SCE-Jan-2014.csv -> (1328, 29)\n",
      "Loaded SCE-Jul-2019.csv -> (1318, 29)\n",
      "Loaded SCE-Dec-2013.csv -> (1350, 29)\n",
      "Loaded SCE-Jul-2018.csv -> (1330, 29)\n",
      "Loaded SCE-Jul-2024.csv -> (1099, 29)\n",
      "Loaded SCE-Jan-2015.csv -> (1308, 29)\n",
      "Loaded SCE-Aug-2013.csv -> (1769, 29)\n",
      "Loaded SCE-Nov-2016.csv -> (1321, 29)\n",
      "Loaded SCE-Mar-2019.csv -> (1368, 29)\n",
      "Loaded SCE-Sep-2019.csv -> (1299, 29)\n",
      "Loaded SCE-Nov-2014.csv -> (1312, 29)\n",
      "Loaded SCE-Jan-2017.csv -> (1358, 29)\n",
      "Loaded SCE-Apr-2019.csv -> (1336, 29)\n",
      "Loaded SCE-May-2018.csv -> (1312, 29)\n",
      "Loaded SCE-May-2024.csv -> (1092, 29)\n",
      "Loaded SCE-May-2019.csv -> (1321, 29)\n",
      "Loaded SCE-Apr-2018.csv -> (1300, 29)\n",
      "Loaded SCE-Apr-2024.csv -> (1082, 29)\n",
      "Loaded SCE-Jan-2016.csv -> (1232, 29)\n",
      "Loaded SCE-Nov-2015.csv -> (1242, 29)\n",
      "Loaded SCE-Sep-2024.csv -> (1089, 29)\n",
      "Loaded SCE-Sep-2018.csv -> (1302, 29)\n",
      "Loaded SCE-Sep-2020.csv -> (1166, 29)\n",
      "Loaded SCE-Mar-2022.csv -> (1273, 29)\n",
      "Loaded SCE-Aug-2014.csv -> (1352, 29)\n",
      "Loaded SCE-Jul-2023.csv -> (1130, 29)\n",
      "Loaded SCE-Apr-2020.csv -> (1300, 29)\n",
      "Loaded SCE-May-2021.csv -> (1234, 29)\n",
      "Loaded SCE-Dec-2015.csv -> (1201, 29)\n",
      "Loaded SCE-Dec-2014.csv -> (1302, 29)\n",
      "Loaded SCE-May-2020.csv -> (1266, 29)\n",
      "Loaded SCE-Apr-2021.csv -> (1243, 29)\n",
      "Loaded SCE-Jul-2022.csv -> (1305, 29)\n",
      "Loaded SCE-Aug-2015.csv -> (1226, 29)\n",
      "Loaded SCE-Mar-2023.csv -> (1254, 29)\n",
      "Loaded SCE-Sep-2021.csv -> (1261, 29)\n",
      "Loaded SCE-Sep-2023.csv -> (1112, 29)\n",
      "Loaded SCE-Mar-2021.csv -> (1221, 29)\n",
      "Loaded SCE-Aug-2017.csv -> (1344, 29)\n",
      "Loaded SCE-Jul-2020.csv -> (1205, 29)\n",
      "Loaded SCE-Apr-2023.csv -> (1255, 29)\n",
      "Loaded SCE-May-2022.csv -> (1215, 29)\n",
      "Loaded SCE-Dec-2016.csv -> (1359, 29)\n",
      "Loaded SCE-Dec-2017.csv -> (1273, 29)\n",
      "Loaded SCE-May-2023.csv -> (1215, 29)\n",
      "Loaded SCE-Apr-2022.csv -> (1269, 29)\n",
      "Loaded SCE-Jul-2021.csv -> (1239, 29)\n",
      "Loaded SCE-Aug-2016.csv -> (1271, 29)\n",
      "Loaded SCE-Nov-2013.csv -> (1541, 29)\n",
      "Loaded SCE-Mar-2020.csv -> (1300, 29)\n",
      "Loaded SCE-Sep-2022.csv -> (1271, 29)\n",
      "Final merged shape: (176101, 30)\n",
      "Final merged shape: (176101, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os  # We'll use os for reliable file path handling\n",
    "\n",
    "# Path to the data directory (relative to the repository root)\n",
    "data_path = 'data'  # Since we're already in the Term-paper folder\n",
    "\n",
    "# Get list of CSV files using os.listdir (more reliable across systems)\n",
    "try:\n",
    "    # Get all files in the data directory\n",
    "    all_files = os.listdir(data_path)\n",
    "    # Filter for CSV files\n",
    "    csv_files = [f for f in all_files if f.lower().endswith('.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print('No CSV files found in', data_path)\n",
    "        merged_df = pd.DataFrame()\n",
    "    else:\n",
    "        dfs = []  # list to store (filename, dataframe) pairs\n",
    "        for fname in csv_files:\n",
    "            full_path = os.path.join(data_path, fname)  # Use os.path.join for reliable path construction\n",
    "            try:\n",
    "                df = pd.read_csv(full_path, sep=';')\n",
    "                dfs.append((fname, df))\n",
    "                print('Loaded', fname, '->', df.shape)\n",
    "            except Exception as e:\n",
    "                print('Failed to read', full_path, ':', e)\n",
    "\n",
    "        # If files were successfully read, merge them\n",
    "        if dfs:\n",
    "            # Start with first DataFrame\n",
    "            merged_df = dfs[0][1]\n",
    "            for name, df in dfs[1:]:\n",
    "                # find common columns to merge on\n",
    "                common = [c for c in merged_df.columns if c in df.columns]\n",
    "                if common:\n",
    "                    # merge on all common columns (outer join to keep data)\n",
    "                    merged_df = pd.merge(merged_df, df, how='outer', on=common)\n",
    "                else:\n",
    "                    # no common columns: concatenate side-by-side\n",
    "                    merged_df = pd.concat([merged_df, df], axis=1)\n",
    "            \n",
    "            print('Final merged shape:', merged_df.shape)\n",
    "        else:\n",
    "            merged_df = pd.DataFrame()\n",
    "            print('No files were successfully read')\n",
    "\n",
    "except Exception as e:\n",
    "    print('Error accessing data directory:', e)\n",
    "    merged_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02051d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "      <th>DATE,CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000220</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000224</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000234</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000238</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70000238</td>\n",
       "      <td>201307</td>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid     wid        date  weight  female  educ   age  hispanic  black  \\\n",
       "0  70000220  201306  2013-06-04    16.3     1.0   3.0  28.0       0.0    1.0   \n",
       "1  70000224  201306  2013-06-03     0.2     0.0   4.0  65.0       0.0    0.0   \n",
       "2  70000234  201306  2013-06-17     4.1     1.0   3.0  41.0       0.0    0.0   \n",
       "3  70000238  201306  2013-06-13     3.0     0.0   3.0  74.0       0.0    0.0   \n",
       "4  70000238  201307  2013-07-10     1.9     0.0   3.0  74.0       0.0    0.0   \n",
       "\n",
       "   couple  ...  num_lit_q3_correct  num_lit_q5  num_lit_q5_correct  \\\n",
       "0     0.0  ...                 0.0       100.0                 1.0   \n",
       "1     1.0  ...                 1.0       100.0                 1.0   \n",
       "2     1.0  ...                 1.0       100.0                 1.0   \n",
       "3     1.0  ...                 1.0         1.0                 0.0   \n",
       "4     NaN  ...                 NaN         NaN                 NaN   \n",
       "\n",
       "   num_lit_q6  num_lit_q6_correct  num_lit_q8  num_lit_q8_correct  num_lit_q9  \\\n",
       "0         5.0                 1.0         NaN                 NaN         NaN   \n",
       "1         5.0                 1.0         NaN                 NaN         NaN   \n",
       "2         5.0                 1.0         NaN                 NaN         NaN   \n",
       "3         5.0                 1.0         NaN                 NaN         NaN   \n",
       "4         NaN                 NaN         NaN                 NaN         NaN   \n",
       "\n",
       "   num_lit_q9_correct  DATE,CPI  \n",
       "0                 NaN       NaN  \n",
       "1                 NaN       NaN  \n",
       "2                 NaN       NaN  \n",
       "3                 NaN       NaN  \n",
       "4                 NaN       NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c79de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
